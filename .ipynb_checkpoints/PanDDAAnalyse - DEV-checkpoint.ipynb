{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Imports\n",
    "import os, sys, configparser\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dls/science/groups/i04-1/conor_dev/ccp4/base/lib/python2.7/site-packages/dask_jobqueue/config.py:12: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Scientific imports\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SGECluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Dataset Crystalography imports\n",
    "import multi_dataset_crystalography as mdc # import MultiCrystalDataset\n",
    "from multi_dataset_crystalography.utils import DefaultPanDDADataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PanDDA imports\n",
    "from pandda_analyse.config import PanDDAConfig\n",
    "from pandda_analyse.event_model import PanDDAEventModel\n",
    "# from pandda_analyse.processor import ProcessModelSeriel\n",
    "from pandda_analyse.event_model_distributed import PanDDAEventModelDistributed, load, fit, evaluate, criticise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "arguments = None\n",
    "# Config\n",
    "config_path = \"/dls/science/groups/i04-1/conor_dev/pandda/lib-python/pandda/pandda_analyse/pandda_analyse/analyse_config.ini\"\n",
    "config = configparser.ConfigParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dls/science/groups/i04-1/conor_dev/pandda/lib-python/pandda/pandda_analyse/pandda_analyse/analyse_config.ini']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.read(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandda_config = PanDDAConfig(config)  # Maps options to code abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "pandda_dataset = mdc.dataset.dataset.MultiCrystalDataset(dataloader=pandda_config.dataloader,\n",
    "                                         sample_loader=pandda_config.sample_loader\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference model\n",
    "reference = pandda_config.get_reference(pandda_dataset.datasets)\n",
    "pandda_dataset.sample_loader.reference = reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transforms to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### PanddaDataChecker ######\n",
      "# # Rejected datasets # #\n",
      "Datasets rejected: \n",
      "PDK2-x0279: rejected - rmsd to reference\n",
      "PDK2-x0251: rejected - rmsd to reference\n",
      "PDK2-x0107: rejected - rmsd to reference\n",
      "PDK2-x0238: rejected - rmsd to reference\n",
      "PDK2-x0878: rejected - rmsd to reference\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply dataset transforms\n",
    "if \"data_check\" in pandda_config.dataset_transforms:\n",
    "    transform = pandda_config.dataset_transforms[\"data_check\"]\n",
    "    dataset = transform(pandda_dataset, reference)\n",
    "    print(\"###### {} ######\".format(transform.name))\n",
    "    for block, record in transform.log().items():\n",
    "        print(\"# # {} # #\".format(block))\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scale_diffraction\" in pandda_config.dataset_transforms:\n",
    "    transform = pandda_config.dataset_transforms[\"scale_diffraction\"]\n",
    "    dataset = transform(dataset, reference)\n",
    "    print(\"###### {} ######\".format(transform.name))\n",
    "    for block, record in transform.log().items():\n",
    "        print(\"# # {} # #\".format(block))\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"filter_structure\" in pandda_config.dataset_transforms:\n",
    "    transform = pandda_config.dataset_transforms[\"filter_structure\"]\n",
    "    dataset = transform(dataset, reference)\n",
    "    print(\"###### {} ######\".format(transform.name))\n",
    "    for block, record in transform.log().items():\n",
    "        print(\"# # {} # #\".format(block))\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"filter_wilson\" in pandda_config.dataset_transforms:\n",
    "    transform = pandda_config.dataset_transforms[\"filter_wilson\"]\n",
    "    dataset = transform(dataset, reference)\n",
    "    print(\"###### {} ######\".format(transform.name))\n",
    "    for block, record in transform.log().items():\n",
    "        print(\"# # {} # #\".format(block))\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"align\" in pandda_config.dataset_transforms:\n",
    "    transform = pandda_config.dataset_transforms[\"align\"]\n",
    "    dataset = transform(dataset, reference)\n",
    "    print(\"###### {} ######\".format(transform.name))\n",
    "    for block, record in transform.log().items():\n",
    "        print(\"# # {} # #\".format(block))\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = pandda_config.pandda_output(dataset)\n",
    "for block, record in pandda_config.pandda_output.log().items():\n",
    "    print(\"####### {} ########\".format(block))\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "pandda_event_model = PanDDAEventModel(pandda_config.statistical_model,\n",
    "                                      pandda_config.clusterer,\n",
    "                                      pandda_config.event_finder,\n",
    "                                      bdc_calculator=pandda_config.bdc_calculator,\n",
    "                                      statistics=[],\n",
    "                                      map_maker=pandda_config.map_maker, \n",
    "                                      event_table_maker=pandda_config.event_table_maker,\n",
    "                                      cpus=config[\"args\"][\"cpus\"],\n",
    "                                      tree=tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.partitions = pandda_config.partitioner(dataset.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit, evaluate, Criticise - Single dataset, Direct eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  VALIDATED!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main Loop\n",
    "# dataloader = DefaultPanDDADataloader(min_train_datasets=60, \n",
    "#                                      max_test_datasets=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx, ds = dataloader(dataset).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = pandda_event_model(idx, ds, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = context.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit()  # Fit the statistical model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtags = model.dataset.partition_samples(\"test\").keys()\n",
    "# truncated_datasets = model.dataset.sample_loader.truncated_datasets\n",
    "# sample_loaders = {dtag: lambda d: model.dataset.sample_loader.get_sample(2.13786674777, d)\n",
    "#                   for dtag\n",
    "#                   in dtags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.evaluate_single(sample_loaders[\"PDK2-x0621\"],\n",
    "#                                truncated_datasets[\"PDK2-x0621\"],\n",
    "#                                model.dataset.sample_loader.ref_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.grid = model.dataset.sample_loader.grid\n",
    "# model.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.criticise_single(sample_loaders[\"PDK2-x0621\"],\n",
    "#                        truncated_datasets[\"PDK2-x0621\"],\n",
    "#                        model.dataset.sample_loader.ref_map,\n",
    "#                        result[2],\n",
    "#                        result[3],\n",
    "#                        tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.dataset.max_res = max([d.data.summary.high_res for dtag, d in model.dataset.datasets.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.criticise_all(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit, evaluate, Criticise - All datasets, Local dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main Loop\n",
    "# dataloader = DefaultPanDDADataloader(min_train_datasets=60, \n",
    "#                                      max_test_datasets=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = [(idx, d) for idx, d in dataloader(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up client\n",
    "# # client = dask.distributed.Client(scheduler_file=\"scheduler.json\")\n",
    "# cluster = LocalCluster(n_workers=2, threads_per_worker=1)\n",
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get base distributed model\n",
    "# pandda_event_model_distributed = PanDDAEventModelDistributed(pandda_config.statistical_model,\n",
    "#                                       pandda_config.clusterer,\n",
    "#                                       pandda_config.event_finder,\n",
    "#                                         dataset=dataset,\n",
    "#                                       bdc_calculator=pandda_config.bdc_calculator,\n",
    "#                                       statistics=[],\n",
    "#                                       map_maker=pandda_config.map_maker, \n",
    "#                                       event_table_maker=pandda_config.event_table_maker,\n",
    "#                                       cpus=config[\"args\"][\"cpus\"],\n",
    "#                                       tree=tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandda_event_model_distributed.instantiate(reference,\n",
    "#                                            tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Instantiate models\n",
    "# models = [pandda_event_model_distributed.clone(dataset=d, \n",
    "#                                    name=idx)\n",
    "#          for idx, d\n",
    "#          in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model moponents\n",
    "# models_loaded = client.map(load,\n",
    "#                     models,\n",
    "#                           pure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load models over nodes\n",
    "# models_fit = client.map(fit, \n",
    "#                            models_loaded,\n",
    "#                        pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ask models to process\n",
    "# models_evaluated = client.map(evaluate, \n",
    "#                               models_fit,\n",
    "#                              pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ask models to criticise\n",
    "# event_tables = client.map(criticise, \n",
    "#                                models_evaluated, \n",
    "#                                pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# event_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_tables_results =[e.result() for e in event_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fi, evaluate, criticise - single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.config.config\n",
    "dask.config.set({\"distributed.admin.tick.limit\": \"120s\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = LocalCluster(n_workers=2, threads_per_worker=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SGECluster(queue=\"medium.q\",\n",
    "                     cores=20,\n",
    "                     processes=5,\n",
    "                           memory=\"64GB\",\n",
    "                           resourcce_spec=\"m_mem_free=64G\",\n",
    "                    python=\"/dls/science/groups/i04-1/conor_dev/ccp4/build/bin/cctbx.python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Loop\n",
    "dataloader = DefaultPanDDADataloader(min_train_datasets=60, \n",
    "                                     max_test_datasets=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = [(idx, d) for idx, d in dataloader(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base distributed model\n",
    "pandda_event_model_distributed = PanDDAEventModelDistributed(pandda_config.statistical_model,\n",
    "                                      pandda_config.clusterer,\n",
    "                                      pandda_config.event_finder,\n",
    "                                        dataset=dataset,\n",
    "                                      bdc_calculator=pandda_config.bdc_calculator,\n",
    "                                      statistics=[],\n",
    "                                      map_maker=pandda_config.map_maker, \n",
    "                                      event_table_maker=pandda_config.event_table_maker,\n",
    "                                      cpus=config[\"args\"][\"cpus\"],\n",
    "                                      tree=tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandda_event_model_distributed.instantiate(reference,\n",
    "#                                            tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = [pandda_event_model_distributed.clone(dataset=d, \n",
    "                                   name=idx)\n",
    "         for idx, d\n",
    "         in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model moponents\n",
    "# model_loaded = load(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = {}\n",
    "\n",
    "# loop over model blocks\n",
    "for model in models:\n",
    "    # Get model name\n",
    "    name = str(model.name)\n",
    "    print(name)\n",
    "    \n",
    "    # Get dataset\n",
    "    dtags = set(model_loaded.dataset.partition_datasets(\"test\").keys()\n",
    "                    + model_loaded.dataset.partition_datasets(\"train\").keys()\n",
    "                    )\n",
    "    \n",
    "    # Get resolution\n",
    "    resolutions_test = max([d.data.summary.high_res for dtag, d\n",
    "                                in model_loaded.dataset.partition_datasets(\"test\").items()])\n",
    "    resolutions_train = max([d.data.summary.high_res for dtag, d\n",
    "                                 in model_loaded.dataset.partition_datasets(\"train\").items()])\n",
    "    max_res = max(resolutions_test, resolutions_train)\n",
    "    \n",
    "    dsk[\"{}_model\".format(name)] = model\n",
    "    dsk[\"reference\"] = reference\n",
    "    dsk[\"tree\"] = tree\n",
    "    \n",
    "        # Load datasets\n",
    "    for dtag in dtags:\n",
    "        dsk[\"{}\".format(dtag.replace(\"-\", \"_\"))] = model.dataset.datasets[dtag]\n",
    "    \n",
    "    # Load model\n",
    "    dsk[\"{}_loaded_model\".format(name)] = (lambda m, r, t: m.instantiate(r, t),\n",
    "                                                       \"{}_model\".format(name),\n",
    "                                                        \"reference\",\n",
    "                                                        \"tree\"\n",
    "                                                      )\n",
    "    \n",
    "    dsk[\"{}_max_res\".format(name)] = max_res\n",
    "    \n",
    "        # Get sample loader\n",
    "    sample_loader = model.dataset.sample_loader\n",
    "    dsk[\"{}_sample_loader\".format(name)] = (lambda m: m.dataset.sample_loader,\n",
    "                                            \"{}_loaded_model\".format(name)\n",
    "                                           )\n",
    "    \n",
    "    # ref map\n",
    "    dsk[\"{}_ref_map\".format(name)] = (lambda sl: sl.ref_map,\n",
    "                                     \"{}_sample_loader\".format(name))\n",
    "    \n",
    "    # Load maps\n",
    "    for dtag in dtags:\n",
    "        dsk[\"{}_{}_map\".format(name, dtag.replace(\"-\", \"_\"))] = (lambda sl, r, _d: sl.get_sample(r, _d), \n",
    "                                               \"{}_sample_loader\".format(name),\n",
    "                                               \"{}_max_res\".format(name), \n",
    "                                               \"{}\".format(dtag.replace(\"-\", \"_\")))\n",
    "    \n",
    "    # Fit model\n",
    "    dsk[\"{}_fit_model\".format(name)] = (lambda m, train, test: m.statistical_model.fit(train, test),\n",
    "                           \"{}_loaded_model\".format(name), \n",
    "                             [\"{}\".format(dtag.replace(\"-\", \"_\")) for dtag, d in model_loaded.dataset.partition_datasets(\"train\").items()], \n",
    "                             [\"{}\".format(dtag.replace(\"-\", \"_\")) for dtag, d in model_loaded.dataset.partition_datasets(\"test\").items()]\n",
    "                          )\n",
    "    \n",
    "    # Find events\n",
    "    for dtag in dtags:\n",
    "        d = \"{}\".format(dtag.replace(\"-\",\"_\"))\n",
    "        dsk[\"{}_{}_events\".format(name, dtag.replace(\"-\",\"_\"))]  = (lambda m, s, _d, ref: m.evaluate_single(s, _d, ref),\n",
    "                                                   \"{}_fit_model\".format(name),\n",
    "                                                   \"{}_{}_map\".format(name, dtag.replace(\"-\",\"_\")),\n",
    "                                                   d,\n",
    "                                                   \"{}_ref_map\".format(name)\n",
    "                                                  )\n",
    "    \n",
    "    # Criticise\n",
    "    for dtag in dtags:\n",
    "        d = \"{}\".format(dtag)\n",
    "        dsk[\"{}_{}_event_table\".format(name, dtag)] = (lambda m, _d, e: m.criticise_single(_d, e),\n",
    "                                                       \"{}_fit_model\".format(name),\n",
    "                                                       d,\n",
    "                                                       \"{}_{}_events\".format(name, dtag)\n",
    "                                                      )\n",
    "    \n",
    "    # Join\n",
    "    dsk[\"{}_event_table\".format(name)] = (lambda m, et: m.criticise_all(et),\n",
    "                            \"{}_fit_model\".format(name),\n",
    "                            [\"{}_{}_events\".format(name, dtag) for dtag in dtags])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk[\"0_loaded_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get(dsk, \"0_loaded_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk[\"0_sample_loader\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get(dsk, \"0_sample_loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get(dsk, \"0_max_res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get(dsk, \"PDK2_x0384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk[\"0_PDK2_x0384_map\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get(dsk, \"0_PDK2_x0384_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk[\"0_fit_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk, \"0_fit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk[\"0_PDK2_x0384_events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk, \"0_PDK2_x0384_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk[\"0_max_res\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk[\"PDK2-x0384\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk, \"0_PDK2-x0384_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk, \"0_event_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk[\"model_loaded\"] = model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtags = set(model_loaded.dataset.partition_datasets(\"test\").keys()\n",
    "                    + model_loaded.dataset.partition_datasets(\"train\").keys()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions_test = max([d.data.summary.high_res for dtag, d\n",
    "                                in model_loaded.dataset.partition_datasets(\"test\").items()])\n",
    "resolutions_train = max([d.data.summary.high_res for dtag, d\n",
    "                                 in model_loaded.dataset.partition_datasets(\"train\").items()])\n",
    "max_res = max(resolutions_test, resolutions_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loader = model_loaded.dataset.sample_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_loaders = {dtag: lambda d: sample_loader.get_sample(res, d)\n",
    "#                           for dtag\n",
    "#                           in dtags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtag in dtags:\n",
    "    dsk[dtag] = (sample_loader.get_sample, max_res, model_loaded.dataset.datasets[dtag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk[\"params\"] = (model_loaded.statistical_model.fit, \n",
    "                 [dtag for dtag, d in model_loaded.dataset.partition_datasets(\"train\").items()], \n",
    "                 [dtag for dtag, d in model_loaded.dataset.partition_datasets(\"test\").items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = client.get(dsk, \"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models over nodes\n",
    "model_fit = client.submit(fit, model_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask models to process\n",
    "model_evaluated = evaluate(model_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluated.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask models to criticise\n",
    "event_tables = criticise(models_evaluated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit, evaluate, Criticise - All datasets, Dask distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SGECluster(queue=\"medium.q\",\n",
    "                     cores=1,\n",
    "                     processes=1,\n",
    "                           memory=\"64GB\",\n",
    "                           resourcce_spec=\"m_mem_free=64G\",\n",
    "                    python=\"/dls/science/groups/i04-1/conor_dev/ccp4/build/bin/cctbx.python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=2, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Loop\n",
    "dataloader = DefaultPanDDADataloader(min_train_datasets=60, \n",
    "                                     max_test_datasets=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = [(idx, d) for idx, d in dataloader(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base distributed model\n",
    "pandda_event_model_distributed = PanDDAEventModelDistributed(pandda_config.statistical_model,\n",
    "                                      pandda_config.clusterer,\n",
    "                                      pandda_config.event_finder,\n",
    "                                        dataset=dataset,\n",
    "                                      bdc_calculator=pandda_config.bdc_calculator,\n",
    "                                      statistics=[],\n",
    "                                      map_maker=pandda_config.map_maker, \n",
    "                                      event_table_maker=pandda_config.event_table_maker,\n",
    "                                      cpus=config[\"args\"][\"cpus\"],\n",
    "                                      tree=tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandda_event_model_distributed.instantiate(reference,\n",
    "                                           tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = [pandda_event_model_distributed.clone(dataset=d, \n",
    "                                   name=idx)\n",
    "         for idx, d\n",
    "         in ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model moponents\n",
    "# models_loaded = client.map(load,\n",
    "#                     models,\n",
    "#                           pure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load models over nodes\n",
    "# models_fit = client.map(fit, \n",
    "#                            models_loaded,\n",
    "#                        pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ask models to process\n",
    "# models_evaluated = client.map(evaluate, \n",
    "#                               models_fit,\n",
    "#                              pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ask models to criticise\n",
    "# event_tables = client.map(criticise, \n",
    "#                                models_evaluated, \n",
    "#                                pure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# event_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_tables_results =[e.result() for e in event_tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = {}\n",
    "for i, model in enumerate(models):\n",
    "    dsk[\"load_{}\".format(i)] = (load, model)\n",
    "    dsk[\"fit_{}\".format(i)] = (fit, \"load_{}\".format(i))\n",
    "    dsk[\"evaluate_{}\".format(i)] = (evaluate, \"fit_{}\".format(i))\n",
    "    dsk[\"criticise_{}\".format(i)] = (criticise, \"evaluate_{}\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk_combined, deps = dask.optimization.fuse(dsk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(dsk_combined, [\"criticise_{}\".format(i)\n",
    "                          for i, model\n",
    "                          in enumerate(models)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask models for events\n",
    "event_tables = event_tables.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessModelSeriel() as P:            \n",
    "\n",
    "    for dataset in dataloader(dataset):\n",
    "\n",
    "        P(pandda_event_model(dataset))\n",
    "        # call with self as model: model.fit(); model.evaluate(); model.criticise()\n",
    "            # Seriel: run immediately\n",
    "            # Qsub: pick model\n",
    "\n",
    "    # exit: \n",
    "        # Seriel: just go on\n",
    "        # qsub: wait for the jobs to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in dataloader(dataset):\n",
    "    \n",
    "    with pandda_event_model(dataset) as model:\n",
    "\n",
    "        # Fit model\n",
    "        print(\"Fitting model\")\n",
    "        model.fit()  # Fit the statistical model\n",
    "\n",
    "        # Evaluate model\n",
    "        model.evaluate_parallel()  # Evaluate the fitted model on maps, fidning events\n",
    "\n",
    "        # Criticise Model\n",
    "        model.criticise() # Stores statistics from model fitting and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticise Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criticise Model\n",
    "pandda_statistics = PanDDARunStatistics(dataset, model)  # Generates statistics from dataset and model\n",
    "PanDDARunGraphs(pandda_statistics)  # Produces a set of graphs of statistics\n",
    "pandda_html = PanDDARunHTML(pandda_statistics)  # Produces a HTML from Statistics\n",
    "PanDDARunLog()  # Produces a log of data processing from dataset, model, graphs and HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with processor as P:            \n",
    "\n",
    "    for dataset in dataloader(dataset):\n",
    "\n",
    "        P(pandda_event_model(dataset))\n",
    "        # call with self as model: model.fit(); model.evaluate(); model.criticise()\n",
    "            # Seriel: run immediately\n",
    "            # Qsub: pick model\n",
    "\n",
    "    # exit: \n",
    "        # Seriel: just go on\n",
    "        # qsub: wait for the jobs to complete\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanDDARunStatistics:\n",
    "    \n",
    "    def __init__(dataset, model):\n",
    "        \n",
    "        self.statistics = [...]\n",
    "        \n",
    "        for statistic in self.statistic:\n",
    "            try:\n",
    "                statistic.calculate()\n",
    "                self.trace[statistic.name] = statistic.log()\n",
    "\n",
    "            except Exeption as e:\n",
    "                self.trace[statistic.name] = \"{}\".format(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputNativeMaps:\n",
    "    \n",
    "    def calculate(samples):\n",
    "        \n",
    "        \n",
    "        \n",
    "    def log():\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cctbx)",
   "language": "python",
   "name": "cctbx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
